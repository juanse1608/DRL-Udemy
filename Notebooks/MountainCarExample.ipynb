{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Car-Mountain-Example\" data-toc-modified-id=\"Car-Mountain-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Car Mountain Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pure-Randomness\" data-toc-modified-id=\"Pure-Randomness-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Pure Randomness</a></span></li><li><span><a href=\"#Intelligent-Symstem\" data-toc-modified-id=\"Intelligent-Symstem-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Intelligent Symstem</a></span></li><li><span><a href=\"#Random-Search\" data-toc-modified-id=\"Random-Search-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Search</a></span></li><li><span><a href=\"#Q-Learning:-Tabular-Method\" data-toc-modified-id=\"Q-Learning:-Tabular-Method-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Q-Learning: Tabular Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Limits-and-Bins\" data-toc-modified-id=\"Limits-and-Bins-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Limits and Bins</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"RBF-NNs-&amp;-Q-Learning-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Functions</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Mountain Example\n",
    "\n",
    "The main idea of this notebook is to interact with the `car_mountain` from [Open AI Gym](https://gym.openai.com/) and treat different algorithms for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T00:22:12.206750Z",
     "start_time": "2020-04-02T00:22:12.199489Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Loading the required libreries\n",
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import io\n",
    "import re\n",
    "import base64\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement, permutations\n",
    "\n",
    "\n",
    "from gym import wrappers\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This section has all the function that I will use in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:35.646977Z",
     "start_time": "2020-03-30T22:01:35.634009Z"
    }
   },
   "outputs": [],
   "source": [
    "#Genera un expand_grid para hacer validacion cruzada\n",
    "def expand_grid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return pd.DataFrame({'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:36.157136Z",
     "start_time": "2020-03-30T22:01:36.151565Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_running_avg(total_rewards):\n",
    "    n = len(total_rewards)\n",
    "    running_avg = []\n",
    "    for idx in range(1,n):\n",
    "        running_avg.append(total_rewards[max(0,idx-100):idx].mean())\n",
    "    plt.plot(running_avg)\n",
    "    plt.title('RUNNIN AVERAGE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Mountain Example\n",
    "\n",
    "This section covers the `car_mountain` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:41.373339Z",
     "start_time": "2020-03-30T22:01:41.356859Z"
    }
   },
   "outputs": [],
   "source": [
    "#My envorinement\n",
    "game = 'Car Mountain'\n",
    "my_env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:41.732983Z",
     "start_time": "2020-03-30T22:01:41.728072Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reset the game, the car in this case\n",
    "obs = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:42.098501Z",
     "start_time": "2020-03-30T22:01:42.086193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the action space: we can take 3 actions, nothing, left, right\n",
    "my_env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Randomness\n",
    "\n",
    "Here we do 1000 iterations and average the result just picking an action between 0 and 1 randomly. As we can see, choicing random actions it is impossible to win the game (always reach the maximum steps allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:22:16.313275Z",
     "start_time": "2020-03-26T16:13:38.836732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 200.0\n",
      "STD OF STEPS: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        my_env.render()\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "    steps_array.append(steps)\n",
    "my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.mean(steps_array))\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent Symstem\n",
    "\n",
    "This section uses an inteligent system in order to determine waht action to take. It's simple:\n",
    "\n",
    "1. If the car has positive velocity and before had postive velocity: move it to the right.\n",
    "2. If the car has positive velocity and before had negative velocity: move it to the right.\n",
    "3. If the car has negative velocity and before had postive velocity: move it to the left.\n",
    "4. If the car has negative velocity and before had negative velocity: move it to the left.\n",
    "\n",
    "This will increase the `momentum`.\n",
    "\n",
    "In order to minimize the number of steps, the `init_action` is taken as a function of the initial postition that takes values in $[-0.4,0.6]$.\n",
    "\n",
    "If `init_pos` > 0.475, then move the car to the left (let it fall). Otherwise, move it to the right following the same idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T19:47:55.388311Z",
     "start_time": "2020-03-26T19:47:55.372447Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T19:48:33.895772Z",
     "start_time": "2020-03-26T19:47:55.762962Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 107.88 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 13.81 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION CUSTOMIZED\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 115.93 WITH INIT ACTION: 1\n",
      "STD OF STEPS: 26.3 WITH INIT ACTION: 1\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 1\n",
      "MAXIMUM OF STEPS: 189 WITH INIT ACTION: 1\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 119.3 WITH INIT ACTION: 2\n",
      "STD OF STEPS: 3.72 WITH INIT ACTION: 2\n",
      "MINIMUM OF STEPS: 113 WITH INIT ACTION: 2\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION: 2\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 130.67 WITH INIT ACTION: 0\n",
      "STD OF STEPS: 32.57 WITH INIT ACTION: 0\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 0\n",
      "MAXIMUM OF STEPS: 192 WITH INIT ACTION: 0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 1\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thorugh visualization it was clear that it is no need to climb to the left corner, now we use the `position` parameter: if the car reach some negative position, we just push it to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:07:13.523380Z",
     "start_time": "2020-03-27T23:07:13.515325Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action_alt(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        if pos < -0.9:\n",
    "            return 2\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:18:06.260424Z",
     "start_time": "2020-03-27T23:18:01.064427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 104.6 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 12.78 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 83 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 116 WITH INIT ACTION CUSTOMIZED\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action_alt(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to do, is hyperparameter tuning for thw two parameters: `init_pos` (in `init_action` decision) and `pos` (in `assign_action` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "Now we will implement a random search for the weights of a linear model with the parameters of the car i.e.\n",
    "\n",
    "$$a = \\sigma(w_0 + w_1c_v + w_2c_p)$$\n",
    "\n",
    "In this example, we do not have bias $w_0$ i.e. $w_0=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:52:30.548674Z",
     "start_time": "2020-03-27T22:52:30.545093Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_action(obs, weights):\n",
    "    x, y = obs\n",
    "    \n",
    "    y = np.dot(obs, weights)\n",
    "    if y > 0:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.493053Z",
     "start_time": "2020-03-27T23:02:30.280599Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vectors and values relevant for final analysis\n",
    "steps_best_sample = None\n",
    "steps_best_avg = math.inf\n",
    "step_avgs = []\n",
    "best_weights = None\n",
    "\n",
    "#init my_env\n",
    "obs = my_env.reset()\n",
    "\n",
    "for r_i in range(10):\n",
    "    \n",
    "    #Init random weights between [-1,1] for each one of the parameters of the models\n",
    "    random_weights = np.random.random(len(obs))*2 - 1 \n",
    "    #print(random_weights)\n",
    "    steps_reps = []\n",
    "    for i in range(100):\n",
    "        obs = my_env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = assign_action(obs, weights=random_weights)\n",
    "            obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps_reps.append(steps)\n",
    "    \n",
    "    step_avgs.append(np.mean(steps_reps))\n",
    "    if np.mean(steps_reps) < steps_best_avg:\n",
    "        steps_best_avg = np.mean(steps_reps)\n",
    "        steps_best_sample = steps_reps\n",
    "        best_weights = random_weights\n",
    "    \n",
    "    if (r_i+1) % 50 == 0:\n",
    "        print('ITERATION NUMBER', r_i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.509015Z",
     "start_time": "2020-03-27T23:02:43.495326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST AVERAGE 200.0 WITH WEIGHTS [-0.90102733  0.16965663]\n"
     ]
    }
   ],
   "source": [
    "print('BEST AVERAGE', steps_best_avg, 'WITH WEIGHTS', best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Random search for weights of linear model does not work very well, at least not as well as out intelligent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning: Tabular Method\n",
    "\n",
    "Let's implement the tabular method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limits and Bins\n",
    "\n",
    "Construction of the bins for each one of the parameters of the model. In particular, given that `pole_vel` and `car_vel` do not have intervals, we will iterate and calculate the `min` and `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T22:01:57.862491Z",
     "start_time": "2020-03-30T22:01:47.433508Z"
    }
   },
   "outputs": [],
   "source": [
    "min_pos, max_pos = [-1.2, 0.6]\n",
    "min_vel, max_vel = [-0.07, 0.07]\n",
    "\n",
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "vels = []\n",
    "pole_vels = []\n",
    "angles = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "my_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the limit for our `box`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:04:21.840637Z",
     "start_time": "2020-03-31T23:04:21.759837Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the bins for each one of the parameters\n",
    "num_bins = 17\n",
    "pos_bins = np.linspace(min_pos, max_pos, num_bins)\n",
    "vel_bins = np.linspace(min_vel, max_vel, num_bins)\n",
    "\n",
    "#Creates a list with the bins of each parameters in the order that the parameters are presented\n",
    "obs_bins = [pos_bins, vel_bins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "Let's create some relevant classes for the __Tabular Method__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:04:22.755829Z",
     "start_time": "2020-03-31T23:04:22.727225Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_q_tab(env, number_of_bins, randomness=True):\n",
    "    n_obs = env.observation_space.shape[0]\n",
    "    n_obs_bins = (number_of_bins+1)**n_obs\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    q_tab = np.random.uniform(-1,1, size=(n_obs_bins, n_actions))\n",
    "    q_tab = pd.DataFrame(q_tab)\n",
    "    \n",
    "    str_l = list(range(0,number_of_bins+1))\n",
    "    combinations = set(list(combinations_with_replacement(str_l*n_obs, n_obs)))\n",
    "    combinations_join = ['-'.join([str(n) for n in c]) for c in combinations]\n",
    "    \n",
    "    q_tab['INDEX'] = combinations_join\n",
    "    \n",
    "    q_tab = q_tab.set_index('INDEX')\n",
    "    return q_tab\n",
    "\n",
    "def build_state(states):\n",
    "    states_str = '-'.join([str(int(s)) for s in states])\n",
    "    return states_str\n",
    "\n",
    "def to_bin(value, my_bin):\n",
    "    return np.digitize(value, my_bin)\n",
    "\n",
    "def transform_obs(obs, obs_bins=obs_bins):\n",
    "    if len(obs) != len(obs_bins):\n",
    "        return 'ERROR'\n",
    "    else:\n",
    "        obs_to_bins = []\n",
    "        for idx,_ in enumerate(obs):\n",
    "            obs_to_bins.append(to_bin(obs[idx], obs_bins[idx]))\n",
    "        return build_state(obs_to_bins)\n",
    "\n",
    "def predict(state, q_tab):\n",
    "    x = transform_obs(state)\n",
    "    return np.array(q_tab.loc[x])\n",
    "\n",
    "def update(state, a, g, q_tab, l_r=0.01):\n",
    "    x = transform_obs(state)\n",
    "    q_tab.loc[x, a] += l_r*(g - q_tab.loc[x, a])\n",
    "    \n",
    "def sample_action(env, state, eps, q_tab):\n",
    "    if np.random.random() < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        a_p = predict(state, q_tab)\n",
    "        return q_tab.columns[np.argmax(np.array(a_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:04:22.968203Z",
     "start_time": "2020-03-31T23:04:22.923773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF Q-TAB IS (324, 3) AND COLUMN NAMES ARE Index([0, 1, 2], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "q_tab = construct_q_tab(env=my_env, number_of_bins=num_bins)\n",
    "q_tab.iloc[:,1] = -10e+5\n",
    "\n",
    "print('SHAPE OF Q-TAB IS', q_tab.shape, 'AND COLUMN NAMES ARE', q_tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:04:23.442640Z",
     "start_time": "2020-03-31T23:04:23.433759Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, q_tab, eps, gamma):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac = sample_action(env, state=obs, eps=eps, q_tab=q_tab)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #We are defining the reward as a function of the original intelligent system implement by us\n",
    "        if (np.sign(vel) != np.sign(pre_vel)) and (ac == pre_ac):\n",
    "            rew = -10000\n",
    "        elif (np.sign(vel) != np.sign(pre_vel)) and (ac != pre_ac):\n",
    "            rew = 10000\n",
    "        elif (np.sign(vel) == np.sign(pre_vel)) and (ac == pre_ac):\n",
    "            rew = 10000\n",
    "        else:\n",
    "            rew = -10000\n",
    "            \n",
    "        #Update the model\n",
    "        g = rew + gamma*np.max(predict(obs, q_tab))\n",
    "        update(state=pre_obs, a=ac, g=g, q_tab=q_tab)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:29:43.528736Z",
     "start_time": "2020-03-31T23:04:27.574280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 ITERATION - -172.76 TOTAL REWARD\n",
      "2000 ITERATION - -165.54 TOTAL REWARD\n",
      "3000 ITERATION - -174.1 TOTAL REWARD\n",
      "4000 ITERATION - -175.04 TOTAL REWARD\n",
      "5000 ITERATION - -172.69 TOTAL REWARD\n",
      "6000 ITERATION - -174.34 TOTAL REWARD\n",
      "7000 ITERATION - -177.15 TOTAL REWARD\n",
      "8000 ITERATION - -168.11 TOTAL REWARD\n",
      "9000 ITERATION - -169.56 TOTAL REWARD\n",
      "10000 ITERATION - -173.7 TOTAL REWARD\n"
     ]
    }
   ],
   "source": [
    "## ITERATE AND LEARN\n",
    "total_rewards = []\n",
    "gamma = 0.9\n",
    "\n",
    "for i in range(10000):\n",
    "    eps = 1.0/np.sqrt(i+1)\n",
    "    total_reward = play_game(env=my_env, q_tab=q_tab, eps=eps, gamma=gamma)\n",
    "    total_rewards.append(total_reward)\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-99:i+1]), 'TOTAL REWARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T23:40:35.552197Z",
     "start_time": "2020-03-31T23:40:35.330384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T23:13:40.732063Z",
     "start_time": "2020-04-02T23:13:40.717398Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T00:01:21.927425Z",
     "start_time": "2020-04-03T00:01:21.921224Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T00:09:13.406274Z",
     "start_time": "2020-04-03T00:09:13.397576Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_models(env, featurizer, scaler, l_r=0.01):\n",
    "    models = []\n",
    "    for i in range(env.action_space.n):\n",
    "        model = SGDRegressor(learning_rate=l_r)\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        state_feature = featurizer.transform(state_scaled)\n",
    "        model.partial_fit(state_feature, [0])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, a, g, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[a].partial_fit(state_feature, [g])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps):\n",
    "    if np.random.random() < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        return np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T00:09:14.050099Z",
     "start_time": "2020-04-03T00:09:14.042400Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler, models=models, eps=eps)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #Update the model\n",
    "        g = rew + gamma*np.max(predict(state=obs, featurizer=featurizer, scaler=scaler, models=models))\n",
    "        update(state=pre_obs, a=ac, g=g, featurizer=featurizer, scaler=scaler, models=models)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T04:52:40.323124Z",
     "start_time": "2020-04-03T04:15:01.828904Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "250 ITERATION - -200.0 100-MOVING AVG REWARD\n",
      "500 ITERATION - -192.02 100-MOVING AVG REWARD\n",
      "750 ITERATION - -179.96 100-MOVING AVG REWARD\n",
      "1000 ITERATION - -161.87 100-MOVING AVG REWARD\n",
      "1250 ITERATION - -150.87 100-MOVING AVG REWARD\n",
      "1500 ITERATION - -146.79 100-MOVING AVG REWARD\n",
      "1750 ITERATION - -140.19 100-MOVING AVG REWARD\n",
      "2000 ITERATION - -138.71 100-MOVING AVG REWARD\n",
      "2250 ITERATION - -134.38 100-MOVING AVG REWARD\n",
      "2500 ITERATION - -136.87 100-MOVING AVG REWARD\n",
      "2750 ITERATION - -123.14 100-MOVING AVG REWARD\n",
      "3000 ITERATION - -122.84 100-MOVING AVG REWARD\n",
      "3250 ITERATION - -117.99 100-MOVING AVG REWARD\n",
      "3500 ITERATION - -115.72 100-MOVING AVG REWARD\n",
      "3750 ITERATION - -111.29 100-MOVING AVG REWARD\n",
      "4000 ITERATION - -111.98 100-MOVING AVG REWARD\n",
      "4250 ITERATION - -113.13 100-MOVING AVG REWARD\n",
      "4500 ITERATION - -117.13 100-MOVING AVG REWARD\n",
      "4750 ITERATION - -116.43 100-MOVING AVG REWARD\n",
      "5000 ITERATION - -119.11 100-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "total_rewards = []\n",
    "l_r = 0.01\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[5.0, 2.5, 1.25, 0.625], num_components=1000)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r)\n",
    "\n",
    "\n",
    "print('READY TO LEARN---')\n",
    "for i in range(5000):\n",
    "    eps = 0.1*(0.9**(i+1))\n",
    "    gamma = 0.9999\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma)\n",
    "    total_rewards.append(total_reward)\n",
    "    if (i+1) % 250 == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-99:i+1]), '100-MOVING AVG REWARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216.484px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
