{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Car-Mountain-Example\" data-toc-modified-id=\"Car-Mountain-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Car Mountain Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pure-Randomness\" data-toc-modified-id=\"Pure-Randomness-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Pure Randomness</a></span></li><li><span><a href=\"#Intelligent-Symstem\" data-toc-modified-id=\"Intelligent-Symstem-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Intelligent Symstem</a></span></li><li><span><a href=\"#Random-Search\" data-toc-modified-id=\"Random-Search-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Search</a></span></li><li><span><a href=\"#Q-Learning:-Tabular-Method\" data-toc-modified-id=\"Q-Learning:-Tabular-Method-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Q-Learning: Tabular Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Limits-and-Bins\" data-toc-modified-id=\"Limits-and-Bins-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Limits and Bins</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"RBF-NNs-&amp;-Q-Learning-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#NNs-&amp;-Q-Learning\" data-toc-modified-id=\"NNs-&amp;-Q-Learning-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#N-Steps-Method:-RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"N-Steps-Method:-RBF-NNs-&amp;-Q-Learning-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>N-Steps Method: RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.7.1\"><span class=\"toc-item-num\">2.7.1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Iterations-and-Learning\" data-toc-modified-id=\"Iterations-and-Learning-2.7.2\"><span class=\"toc-item-num\">2.7.2&nbsp;&nbsp;</span>Iterations and Learning</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Mountain Example\n",
    "\n",
    "The main idea of this notebook is to interact with the `car_mountain` from [Open AI Gym](https://gym.openai.com/) and treat different algorithms for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:31:49.190657Z",
     "start_time": "2020-04-09T15:31:49.183665Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Loading the required libreries\n",
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import re\n",
    "import base64\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as tensor\n",
    "from itertools import combinations_with_replacement, permutations\n",
    "\n",
    "\n",
    "from tensorflow.keras.initializers import RandomUniform, Initializer, Constant\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from gym import wrappers\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This section has all the function that I will use in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.540545Z",
     "start_time": "2020-04-09T14:59:57.530940Z"
    }
   },
   "outputs": [],
   "source": [
    "#Genera un expand_grid para hacer validacion cruzada\n",
    "def expand_grid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return pd.DataFrame({'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.551865Z",
     "start_time": "2020-04-09T14:59:57.543039Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_running_avg(total_rewards):\n",
    "    n = len(total_rewards)\n",
    "    running_avg = []\n",
    "    for idx in range(1,n):\n",
    "        running_avg.append(total_rewards[max(0,idx-100):idx].mean())\n",
    "    plt.plot(running_avg)\n",
    "    plt.title('RUNNING AVERAGE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Mountain Example\n",
    "\n",
    "This section covers the `car_mountain` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.570753Z",
     "start_time": "2020-04-09T14:59:57.553997Z"
    }
   },
   "outputs": [],
   "source": [
    "#My envorinement\n",
    "game = 'Car Mountain'\n",
    "my_env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.580548Z",
     "start_time": "2020-04-09T14:59:57.572622Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reset the game, the car in this case\n",
    "obs = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.599078Z",
     "start_time": "2020-04-09T14:59:57.584123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the action space: we can take 3 actions, nothing, left, right\n",
    "my_env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Randomness\n",
    "\n",
    "Here we do 1000 iterations and average the result just picking an action between 0 and 1 randomly. As we can see, choicing random actions it is impossible to win the game (always reach the maximum steps allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:22:16.313275Z",
     "start_time": "2020-03-26T16:13:38.836732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 200.0\n",
      "STD OF STEPS: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        my_env.render()\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "    steps_array.append(steps)\n",
    "my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.mean(steps_array))\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent Symstem\n",
    "\n",
    "This section uses an inteligent system in order to determine waht action to take. It's simple:\n",
    "\n",
    "1. If the car has positive velocity and before had postive velocity: move it to the right.\n",
    "2. If the car has positive velocity and before had negative velocity: move it to the right.\n",
    "3. If the car has negative velocity and before had postive velocity: move it to the left.\n",
    "4. If the car has negative velocity and before had negative velocity: move it to the left.\n",
    "\n",
    "This will increase the `momentum`.\n",
    "\n",
    "In order to minimize the number of steps, the `init_action` is taken as a function of the initial postition that takes values in $[-0.4,0.6]$.\n",
    "\n",
    "If `init_pos` > 0.475, then move the car to the left (let it fall). Otherwise, move it to the right following the same idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:22.528629Z",
     "start_time": "2020-04-03T22:35:22.520076Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:45.786040Z",
     "start_time": "2020-04-03T22:35:22.963749Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 107.98 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 13.98 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION CUSTOMIZED\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 114.72 WITH INIT ACTION: 1\n",
      "STD OF STEPS: 25.82 WITH INIT ACTION: 1\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 1\n",
      "MAXIMUM OF STEPS: 195 WITH INIT ACTION: 1\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 119.42 WITH INIT ACTION: 2\n",
      "STD OF STEPS: 3.71 WITH INIT ACTION: 2\n",
      "MINIMUM OF STEPS: 113 WITH INIT ACTION: 2\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION: 2\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 128.14 WITH INIT ACTION: 0\n",
      "STD OF STEPS: 32.92 WITH INIT ACTION: 0\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 0\n",
      "MAXIMUM OF STEPS: 189 WITH INIT ACTION: 0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 1\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thorugh visualization it was clear that it is no need to climb to the left corner, now we use the `position` parameter: if the car reach some negative position, we just push it to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:45.803294Z",
     "start_time": "2020-04-03T22:35:45.787817Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action_alt(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        if pos < -0.9:\n",
    "            return 2\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:57:38.859976Z",
     "start_time": "2020-04-03T22:57:34.762912Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 104.7 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 12.76 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 83 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 116 WITH INIT ACTION CUSTOMIZED\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action_alt(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "best_avg_reward = np.mean(steps_array)\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to do, is hyperparameter tuning for thw two parameters: `init_pos` (in `init_action` decision) and `pos` (in `assign_action` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "Now we will implement a random search for the weights of a linear model with the parameters of the car i.e.\n",
    "\n",
    "$$a = \\sigma(w_0 + w_1c_v + w_2c_p)$$\n",
    "\n",
    "In this example, we do not have bias $w_0$ i.e. $w_0=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:52:30.548674Z",
     "start_time": "2020-03-27T22:52:30.545093Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_action(obs, weights):\n",
    "    x, y = obs\n",
    "    \n",
    "    y = np.dot(obs, weights)\n",
    "    if y > 0:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.493053Z",
     "start_time": "2020-03-27T23:02:30.280599Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vectors and values relevant for final analysis\n",
    "steps_best_sample = None\n",
    "steps_best_avg = math.inf\n",
    "step_avgs = []\n",
    "best_weights = None\n",
    "\n",
    "#init my_env\n",
    "obs = my_env.reset()\n",
    "\n",
    "for r_i in range(10):\n",
    "    \n",
    "    #Init random weights between [-1,1] for each one of the parameters of the models\n",
    "    random_weights = np.random.random(len(obs))*2 - 1 \n",
    "    #print(random_weights)\n",
    "    steps_reps = []\n",
    "    for i in range(100):\n",
    "        obs = my_env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = assign_action(obs, weights=random_weights)\n",
    "            obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps_reps.append(steps)\n",
    "    \n",
    "    step_avgs.append(np.mean(steps_reps))\n",
    "    if np.mean(steps_reps) < steps_best_avg:\n",
    "        steps_best_avg = np.mean(steps_reps)\n",
    "        steps_best_sample = steps_reps\n",
    "        best_weights = random_weights\n",
    "    \n",
    "    if (r_i+1) % 50 == 0:\n",
    "        print('ITERATION NUMBER', r_i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.509015Z",
     "start_time": "2020-03-27T23:02:43.495326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST AVERAGE 200.0 WITH WEIGHTS [-0.90102733  0.16965663]\n"
     ]
    }
   ],
   "source": [
    "print('BEST AVERAGE', steps_best_avg, 'WITH WEIGHTS', best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Random search for weights of linear model does not work very well, at least not as well as out intelligent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning: Tabular Method\n",
    "\n",
    "Let's implement the tabular method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limits and Bins\n",
    "\n",
    "Construction of the bins for each one of the parameters of the model. In particular, given that `pole_vel` and `car_vel` do not have intervals, we will iterate and calculate the `min` and `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:26:44.038441Z",
     "start_time": "2020-04-06T03:26:33.305088Z"
    }
   },
   "outputs": [],
   "source": [
    "min_pos, max_pos = [-1.2, 0.6]\n",
    "min_vel, max_vel = [-0.07, 0.07]\n",
    "\n",
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "vels = []\n",
    "pole_vels = []\n",
    "angles = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "my_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the limit for our `box`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:07.858566Z",
     "start_time": "2020-04-06T04:22:07.849758Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the bins for each one of the parameters\n",
    "num_bins = 10\n",
    "pos_bins = np.linspace(min_pos, max_pos, num_bins)\n",
    "vel_bins = np.linspace(min_vel, max_vel, num_bins)\n",
    "\n",
    "#Creates a list with the bins of each parameters in the order that the parameters are presented\n",
    "obs_bins = [pos_bins, vel_bins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "Let's create some relevant classes for the __Tabular Method__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:08.637991Z",
     "start_time": "2020-04-06T04:22:08.619742Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_q_tab(env, number_of_bins, randomness=True):\n",
    "    n_obs = env.observation_space.shape[0]\n",
    "    n_obs_bins = (number_of_bins+1)**n_obs\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    q_tab = np.random.uniform(-1,1, size=(n_obs_bins, n_actions))\n",
    "    q_tab = pd.DataFrame(q_tab)\n",
    "    \n",
    "    str_l = list(range(0,number_of_bins+1))\n",
    "    combinations = set(list(combinations_with_replacement(str_l*n_obs, n_obs)))\n",
    "    combinations_join = ['-'.join([str(n) for n in c]) for c in combinations]\n",
    "    \n",
    "    q_tab['INDEX'] = combinations_join\n",
    "    \n",
    "    q_tab = q_tab.set_index('INDEX')\n",
    "    return q_tab\n",
    "\n",
    "def build_state(states):\n",
    "    states_str = '-'.join([str(int(s)) for s in states])\n",
    "    return states_str\n",
    "\n",
    "def to_bin(value, my_bin):\n",
    "    return np.digitize(value, my_bin)\n",
    "\n",
    "def transform_obs(obs, obs_bins=obs_bins):\n",
    "    if len(obs) != len(obs_bins):\n",
    "        return 'ERROR'\n",
    "    else:\n",
    "        obs_to_bins = []\n",
    "        for idx,_ in enumerate(obs):\n",
    "            obs_to_bins.append(to_bin(obs[idx], obs_bins[idx]))\n",
    "        return build_state(obs_to_bins)\n",
    "\n",
    "def predict(state, q_tab):\n",
    "    x = transform_obs(state)\n",
    "    return np.array(q_tab.loc[x])\n",
    "\n",
    "def update(state, a, g, q_tab, l_r=0.01):\n",
    "    x = transform_obs(state)\n",
    "    q_tab.loc[x, a] += l_r*(g - q_tab.loc[x, a])\n",
    "    \n",
    "def sample_action(env, state, eps, q_tab):\n",
    "    if np.random.random() < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        a_p = predict(state, q_tab)\n",
    "        return q_tab.columns[np.argmax(np.array(a_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:09.101403Z",
     "start_time": "2020-04-06T04:22:09.090968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF Q-TAB IS (121, 3) AND COLUMN NAMES ARE Index([0, 1, 2], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "q_tab = construct_q_tab(env=my_env, number_of_bins=num_bins)\n",
    "q_tab.iloc[:,1] = -10e+5\n",
    "\n",
    "print('SHAPE OF Q-TAB IS', q_tab.shape, 'AND COLUMN NAMES ARE', q_tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:17.108859Z",
     "start_time": "2020-04-06T04:22:17.101166Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, q_tab, eps, gamma):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac = sample_action(env, state=obs, eps=eps, q_tab=q_tab)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        if (steps==199):\n",
    "            rew = -100\n",
    "            \n",
    "        \n",
    "        if done and (steps<199):\n",
    "            rew = 1000\n",
    "        \n",
    "        #Update the model\n",
    "        g = rew + gamma*np.max(predict(obs, q_tab))\n",
    "        update(state=pre_obs, a=ac, g=g, q_tab=q_tab)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:30:29.222687Z",
     "start_time": "2020-04-06T04:22:17.314370Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ITERATION - -200.0 TOTAL REWARD\n",
      "200 ITERATION - -200.0 TOTAL REWARD\n",
      "300 ITERATION - -200.0 TOTAL REWARD\n",
      "400 ITERATION - -198.39 TOTAL REWARD\n",
      "500 ITERATION - -198.16 TOTAL REWARD\n",
      "600 ITERATION - -200.0 TOTAL REWARD\n",
      "700 ITERATION - -193.41 TOTAL REWARD\n",
      "800 ITERATION - -187.08 TOTAL REWARD\n",
      "900 ITERATION - -185.92 TOTAL REWARD\n",
      "1000 ITERATION - -173.35 TOTAL REWARD\n",
      "1100 ITERATION - -171.69 TOTAL REWARD\n",
      "1200 ITERATION - -170.16 TOTAL REWARD\n",
      "1300 ITERATION - -173.01 TOTAL REWARD\n",
      "1400 ITERATION - -178.13 TOTAL REWARD\n",
      "1500 ITERATION - -184.87 TOTAL REWARD\n",
      "1600 ITERATION - -173.76 TOTAL REWARD\n",
      "1700 ITERATION - -180.77 TOTAL REWARD\n",
      "1800 ITERATION - -176.7 TOTAL REWARD\n",
      "1900 ITERATION - -166.88 TOTAL REWARD\n",
      "2000 ITERATION - -172.68 TOTAL REWARD\n",
      "2100 ITERATION - -162.66 TOTAL REWARD\n",
      "2200 ITERATION - -163.14 TOTAL REWARD\n",
      "2300 ITERATION - -164.19 TOTAL REWARD\n",
      "2400 ITERATION - -176.29 TOTAL REWARD\n",
      "2500 ITERATION - -158.33 TOTAL REWARD\n"
     ]
    }
   ],
   "source": [
    "## ITERATE AND LEARN\n",
    "total_rewards = []\n",
    "gamma = 0.9999\n",
    "\n",
    "for i in range(2500):\n",
    "    eps = 1.0/np.sqrt(i+1)\n",
    "    total_reward = play_game(env=my_env, q_tab=q_tab, eps=eps, gamma=gamma)\n",
    "    total_rewards.append(total_reward)\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-99:i+1]), 'TOTAL REWARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:30:32.173768Z",
     "start_time": "2020-04-06T04:30:31.856455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:04.898661Z",
     "start_time": "2020-04-10T03:20:04.881555Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:05.471821Z",
     "start_time": "2020-04-10T03:20:05.454208Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:12.905067Z",
     "start_time": "2020-04-10T03:20:12.880362Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_models(env, featurizer, scaler, n_actions=None,l_r=0.01):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        model = SGDRegressor(learning_rate=l_r)\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        state_feature = featurizer.transform(state_scaled)\n",
    "        model.partial_fit(state_feature, [0])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_feature, [g])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        \n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:17.833306Z",
     "start_time": "2020-04-10T03:20:17.818579Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma, n_actions=None, actions=None, updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #Update the model\n",
    "        if updt:\n",
    "            g = rew + gamma*np.max(predict(state=obs, featurizer=featurizer, scaler=scaler, models=models))\n",
    "            update(state=pre_obs, idx_a=idx_ac, g=g, featurizer=featurizer, scaler=scaler, models=models)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T04:05:01.144374Z",
     "start_time": "2020-04-10T03:53:50.499247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "50 ITERATION - -200.0 50-MOVING AVG REWARD\n",
      "100 ITERATION - -196.02 50-MOVING AVG REWARD\n",
      "150 ITERATION - -150.92 50-MOVING AVG REWARD\n",
      "200 ITERATION - -138.9 50-MOVING AVG REWARD\n",
      "250 ITERATION - -123.52 50-MOVING AVG REWARD\n",
      "300 ITERATION - -129.62 50-MOVING AVG REWARD\n",
      "350 ITERATION - -124.72 50-MOVING AVG REWARD\n",
      "400 ITERATION - -127.64 50-MOVING AVG REWARD\n",
      "450 ITERATION - -122.56 50-MOVING AVG REWARD\n",
      "500 ITERATION - -122.58 50-MOVING AVG REWARD\n",
      "550 ITERATION - -119.2 50-MOVING AVG REWARD\n",
      "600 ITERATION - -117.56 50-MOVING AVG REWARD\n",
      "650 ITERATION - -117.46 50-MOVING AVG REWARD\n",
      "700 ITERATION - -114.08 50-MOVING AVG REWARD\n",
      "750 ITERATION - -115.36 50-MOVING AVG REWARD\n",
      "800 ITERATION - -113.56 50-MOVING AVG REWARD\n",
      "850 ITERATION - -113.76 50-MOVING AVG REWARD\n",
      "900 ITERATION - -111.76 50-MOVING AVG REWARD\n",
      "950 ITERATION - -111.4 50-MOVING AVG REWARD\n",
      "1000 ITERATION - -109.52 50-MOVING AVG REWARD\n",
      "1050 ITERATION - -109.68 50-MOVING AVG REWARD\n",
      "1100 ITERATION - -105.24 50-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 'invscaling'\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 10000\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 50\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[0.5, 0.4, 0.3, 0.2, 0.1, 0.05],\n",
    "                               num_components=75)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r, n_actions=len(actions))\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.1*(0.9**(i+1))\n",
    "    gamma = 0.99\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T04:06:20.446943Z",
     "start_time": "2020-04-10T04:06:05.523350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO CHECK---\n",
      "ITERATION 25\n",
      "ITERATION 50\n",
      "ITERATION 75\n",
      "ITERATION 100\n",
      "RESULTS---\n",
      "AVERAGE OF REWARD: -108.67\n",
      "STD OF REWARD: 10.95\n",
      "MINIMUM OF REWARD: -116.0\n",
      "MAXIMUM OF REWARD: -83.0\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing results produced by our __RBF Neural Network__ with a pretty good avergare reward (compared with our best intelligent system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs & Q-Learning\n",
    "\n",
    "In this section, I'll create a Neural Network a let that the it learn its own features instead of providing it the radial basis kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:30:08.624519Z",
     "start_time": "2020-04-09T15:30:08.617548Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T23:10:57.079937Z",
     "start_time": "2020-04-09T23:10:57.063194Z"
    }
   },
   "outputs": [],
   "source": [
    "#We only modify our sgd_regressor class using Theano code \n",
    "class NN():\n",
    "    def __init__(self, input_shape, l_r=0.01, layers=[50, 100, 100, 50],\n",
    "                 drop_out=0.1):\n",
    "        self.l_r = l_r\n",
    "        self.step = 0\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.sgd = SGD(lr=l_r, decay=0)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(units=self.layers[0], input_shape=input_shape, activation='tanh',\n",
    "                             kernel_initializer='lecun_uniform'))\n",
    "        for idx in range(1,len(layers)):\n",
    "            self.model.add(Dense(self.layers[idx], activation='tanh'))\n",
    "            if drop_out:\n",
    "                self.model.add(Dropout(drop_out))\n",
    "        \n",
    "        self.model.add(Dense(1, activation='tanh'))\n",
    "        \n",
    "        self.model.compile(loss='mse', optimizer=self.sgd)\n",
    "        \n",
    "    def partial_fit(self, x, y):\n",
    "        mod_x = x\n",
    "        mod_y = y.reshape(y.shape[0],1)\n",
    "        self.model.train_on_batch(mod_x, mod_y)\n",
    "        self.step += 1\n",
    "        \n",
    "    def predict(self, x):\n",
    "        mod_x = x\n",
    "        return self.model.predict(mod_x)[0]\n",
    "\n",
    "def init_models(env, scaler, n_actions=None, l_r=0.01, layers=[50, 100, 100, 50], drop_out=0.1):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        input_shape = state_scaled[0].shape\n",
    "        model = NN(l_r=l_r, input_shape=input_shape, layers=layers, drop_out=drop_out)\n",
    "        #model.partial_fit(scaled, [0])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_scaled)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_scaled, np.array([g]))\n",
    "    \n",
    "def sample_action(env, state, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, scaler, models)\n",
    "        \n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T23:48:39.225438Z",
     "start_time": "2020-04-09T23:48:39.208225Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, scaler, eps, gamma, n_actions=None, actions=None, updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #Update the model\n",
    "        if updt:\n",
    "            g = (rew + gamma*np.max(predict(state=obs, scaler=scaler, models=models)))\n",
    "            update(state=pre_obs, idx_a=idx_ac, g=g, scaler=scaler, models=models)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    \n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T00:40:55.799398Z",
     "start_time": "2020-04-09T23:48:40.084612Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "10 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "20 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "30 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "40 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "50 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "60 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "70 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "80 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "90 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "100 ITERATION - -200.0 10-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 0.01\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 50\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "models = init_models(env=my_env, scaler=scaler, l_r=l_r, n_actions=len(actions),\n",
    "                     layers=[1000, 1000], drop_out=0.01)\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.1*(0.9**(i+1))\n",
    "    gamma = 0.99\n",
    "    total_reward = play_game(env=my_env, models=models, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T22:26:48.915055Z",
     "start_time": "2020-04-09T22:26:28.087Z"
    }
   },
   "outputs": [],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was expecting, the result are pretty bad, it is like the NN is suffering the __Catastrofic Frogetting__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Steps Method: RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T05:28:14.202175Z",
     "start_time": "2020-04-10T05:28:14.196932Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T05:28:14.727567Z",
     "start_time": "2020-04-10T05:28:14.721230Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T17:46:46.989507Z",
     "start_time": "2020-04-10T17:46:46.965007Z"
    }
   },
   "outputs": [],
   "source": [
    "# class sgd_regressor():\n",
    "#     def __init__(self, n_weights, l_r=0.01):\n",
    "#         self.weights = np.random.rand(n_weights)/np.power(n_weights, 0.5)\n",
    "#         self.l_r = l_r\n",
    "#         self.step = 0\n",
    "        \n",
    "    \n",
    "#     def partial_fit(self, x, y):\n",
    "#         estimated = x.dot(self.weights)\n",
    "#         gradient = (y - estimated).dot(x)\n",
    "#         self.weights += (self.l_r)*gradient\n",
    "#         self.step += 1\n",
    "    \n",
    "#     def predict(self, x):\n",
    "#         return x.dot(self.weights)\n",
    "\n",
    "    \n",
    "def init_models(env, featurizer, scaler, n_actions=None, l_r='invscaling', eta=0.01):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        model = SGDRegressor(learning_rate=l_r, eta0=eta)\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        state_feature = featurizer.transform(state_scaled)\n",
    "        model.partial_fit(state_feature, [0])\n",
    "        models.append(model)\n",
    "    return models    \n",
    "    \n",
    "# def init_models(env, n_weights, featurizer, scaler, n_actions=None, l_r=0.01):\n",
    "#     models = []\n",
    "#     if n_actions==None:\n",
    "#         n_actions = env.action_space.n\n",
    "    \n",
    "#     for i in range(n_actions):\n",
    "#         model = sgd_regressor(n_weights=n_weights, l_r=l_r)\n",
    "#         state_scaled = scaler.transform([env.reset()])\n",
    "#         state_feature = featurizer.transform(state_scaled)\n",
    "#         models.append(model)\n",
    "#     return models\n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_feature, [g])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T17:21:32.212704Z",
     "start_time": "2020-04-11T17:21:32.170631Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma, steps=5, n_actions=None, actions=None,\n",
    "              updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rewards = []\n",
    "    iters = 0\n",
    "    states = []\n",
    "    idx_actions = []\n",
    "    total_reward = 0\n",
    "    \n",
    "    gammas = np.repeat(gamma, steps)**np.arange(steps)\n",
    "    #print(gammas)\n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        states.append(obs)\n",
    "        idx_actions.append(idx_ac)\n",
    "        \n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        \n",
    "        rewards.append(rew)\n",
    "        \n",
    "        if updt:\n",
    "            if len(rewards) >= steps:\n",
    "                rew_accumulated = gammas.dot(rewards[-steps:])\n",
    "                g = rew_accumulated + (gamma**steps)*(np.max(predict(state=obs, featurizer=featurizer,\n",
    "                                                             scaler=scaler, models=models)))\n",
    "                update(state=states[-steps], idx_a=idx_actions[-steps], g=g, featurizer=featurizer,\n",
    "                       scaler=scaler, models=models)\n",
    "        total_reward += rew\n",
    "        iters += 1\n",
    "    \n",
    "    if updt and (steps > 1):\n",
    "        rewards = rewards[-steps+1:]\n",
    "        idx_actions = idx_actions[-steps+1:]\n",
    "        states = states[-steps+1:]\n",
    "        if iters <= 199:\n",
    "            #rewards[-1] = 1\n",
    "            while len(rewards) > 0:\n",
    "                rew_accumulated = gammas[:len(rewards)].dot(rewards)\n",
    "                g = rew_accumulated\n",
    "                update(state=states[0], idx_a=idx_actions[0], g=g, featurizer=featurizer, scaler=scaler,\n",
    "                       models=models)\n",
    "                rewards.pop(0)\n",
    "                idx_actions.pop(0)\n",
    "                states.pop(0)\n",
    "        else:\n",
    "            while len(rewards) > 0:\n",
    "                rew_accumulated = gammas.dot(rewards + [-1000]*(steps - len(rewards)))\n",
    "                g = rew_accumulated\n",
    "                update(state=states[0], idx_a=idx_actions[0], g=g, featurizer=featurizer, scaler=scaler,\n",
    "                       models=models)\n",
    "                rewards.pop(0)\n",
    "                idx_actions.pop(0)\n",
    "                states.pop(0)\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations and Learning\n",
    "\n",
    "This section implements our learning algorithm and check its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T17:40:16.851693Z",
     "start_time": "2020-04-11T17:38:52.809067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "100 ITERATION - -157.51 100-MOVING AVG REWARD\n",
      "200 ITERATION - -121.98 100-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 'constant'\n",
    "eta = 0.0005\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 200\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 100\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[0.5, 0.4, 0.3, 0.2, 0.1, 0.05],\n",
    "                               num_components=75)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "n_weights = featurization['TRANSFORM_FEATURES'].shape[1]\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r, n_actions=len(actions),\n",
    "                     eta=eta)\n",
    "\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.01*(0.9**(i+1))\n",
    "    gamma = 0.95\n",
    "    steps = 3\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, steps=steps)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T17:40:17.040701Z",
     "start_time": "2020-04-11T17:40:16.853596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T18:11:20.222933Z",
     "start_time": "2020-04-11T18:11:08.464619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO CHECK---\n",
      "ITERATION 25\n",
      "ITERATION 50\n",
      "ITERATION 75\n",
      "ITERATION 100\n",
      "RESULTS---\n",
      "AVERAGE OF REWARD: -115.64\n",
      "STD OF REWARD: 12.48\n",
      "MINIMUM OF REWARD: -197.0\n",
      "MAXIMUM OF REWARD: -111.0\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
