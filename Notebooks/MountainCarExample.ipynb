{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Car-Mountain-Example\" data-toc-modified-id=\"Car-Mountain-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Car Mountain Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pure-Randomness\" data-toc-modified-id=\"Pure-Randomness-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Pure Randomness</a></span></li><li><span><a href=\"#Intelligent-Symstem\" data-toc-modified-id=\"Intelligent-Symstem-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Intelligent Symstem</a></span></li><li><span><a href=\"#Random-Search\" data-toc-modified-id=\"Random-Search-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Search</a></span></li><li><span><a href=\"#Q-Learning:-Tabular-Method\" data-toc-modified-id=\"Q-Learning:-Tabular-Method-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Q-Learning: Tabular Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Limits-and-Bins\" data-toc-modified-id=\"Limits-and-Bins-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Limits and Bins</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"RBF-NNs-&amp;-Q-Learning-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#NNs-&amp;-Q-Learning\" data-toc-modified-id=\"NNs-&amp;-Q-Learning-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#N-Steps-Method:-RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"N-Steps-Method:-RBF-NNs-&amp;-Q-Learning-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>N-Steps Method: RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.7.1\"><span class=\"toc-item-num\">2.7.1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Iterations-and-Learning\" data-toc-modified-id=\"Iterations-and-Learning-2.7.2\"><span class=\"toc-item-num\">2.7.2&nbsp;&nbsp;</span>Iterations and Learning</a></span></li></ul></li><li><span><a href=\"#TD-Lambda-Method:-RBF-NNs-&amp;-Q-Learning\" data-toc-modified-id=\"TD-Lambda-Method:-RBF-NNs-&amp;-Q-Learning-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>TD-Lambda Method: RBF NNs &amp; Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.8.1\"><span class=\"toc-item-num\">2.8.1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Iterations-and-Learning\" data-toc-modified-id=\"Iterations-and-Learning-2.8.2\"><span class=\"toc-item-num\">2.8.2&nbsp;&nbsp;</span>Iterations and Learning</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Mountain Example\n",
    "\n",
    "The main idea of this notebook is to interact with the `car_mountain` from [Open AI Gym](https://gym.openai.com/) and treat different algorithms for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:31:49.190657Z",
     "start_time": "2020-04-09T15:31:49.183665Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Loading the required libreries\n",
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import re\n",
    "import base64\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as tensor\n",
    "from itertools import combinations_with_replacement, permutations\n",
    "\n",
    "\n",
    "from tensorflow.keras.initializers import RandomUniform, Initializer, Constant\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from gym import wrappers\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This section has all the function that I will use in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.540545Z",
     "start_time": "2020-04-09T14:59:57.530940Z"
    }
   },
   "outputs": [],
   "source": [
    "#Genera un expand_grid para hacer validacion cruzada\n",
    "def expand_grid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return pd.DataFrame({'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.551865Z",
     "start_time": "2020-04-09T14:59:57.543039Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_running_avg(total_rewards):\n",
    "    n = len(total_rewards)\n",
    "    running_avg = []\n",
    "    for idx in range(1,n):\n",
    "        running_avg.append(total_rewards[max(0,idx-100):idx].mean())\n",
    "    plt.plot(running_avg)\n",
    "    plt.title('RUNNING AVERAGE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Mountain Example\n",
    "\n",
    "This section covers the `car_mountain` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.570753Z",
     "start_time": "2020-04-09T14:59:57.553997Z"
    }
   },
   "outputs": [],
   "source": [
    "#My envorinement\n",
    "game = 'Car Mountain'\n",
    "my_env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.580548Z",
     "start_time": "2020-04-09T14:59:57.572622Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reset the game, the car in this case\n",
    "obs = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:59:57.599078Z",
     "start_time": "2020-04-09T14:59:57.584123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the action space: we can take 3 actions, nothing, left, right\n",
    "my_env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Randomness\n",
    "\n",
    "Here we do 1000 iterations and average the result just picking an action between 0 and 1 randomly. As we can see, choicing random actions it is impossible to win the game (always reach the maximum steps allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:22:16.313275Z",
     "start_time": "2020-03-26T16:13:38.836732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 200.0\n",
      "STD OF STEPS: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        my_env.render()\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "    steps_array.append(steps)\n",
    "my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.mean(steps_array))\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent Symstem\n",
    "\n",
    "This section uses an inteligent system in order to determine waht action to take. It's simple:\n",
    "\n",
    "1. If the car has positive velocity and before had postive velocity: move it to the right.\n",
    "2. If the car has positive velocity and before had negative velocity: move it to the right.\n",
    "3. If the car has negative velocity and before had postive velocity: move it to the left.\n",
    "4. If the car has negative velocity and before had negative velocity: move it to the left.\n",
    "\n",
    "This will increase the `momentum`.\n",
    "\n",
    "In order to minimize the number of steps, the `init_action` is taken as a function of the initial postition that takes values in $[-0.4,0.6]$.\n",
    "\n",
    "If `init_pos` > 0.475, then move the car to the left (let it fall). Otherwise, move it to the right following the same idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:22.528629Z",
     "start_time": "2020-04-03T22:35:22.520076Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:45.786040Z",
     "start_time": "2020-04-03T22:35:22.963749Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 107.98 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 13.98 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION CUSTOMIZED\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 114.72 WITH INIT ACTION: 1\n",
      "STD OF STEPS: 25.82 WITH INIT ACTION: 1\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 1\n",
      "MAXIMUM OF STEPS: 195 WITH INIT ACTION: 1\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 119.42 WITH INIT ACTION: 2\n",
      "STD OF STEPS: 3.71 WITH INIT ACTION: 2\n",
      "MINIMUM OF STEPS: 113 WITH INIT ACTION: 2\n",
      "MAXIMUM OF STEPS: 125 WITH INIT ACTION: 2\n",
      "\n",
      "\n",
      "AVERAGE OF STEPS: 128.14 WITH INIT ACTION: 0\n",
      "STD OF STEPS: 32.92 WITH INIT ACTION: 0\n",
      "MINIMUM OF STEPS: 86 WITH INIT ACTION: 0\n",
      "MAXIMUM OF STEPS: 189 WITH INIT ACTION: 0\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 1\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION:', init_action)\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION:', init_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thorugh visualization it was clear that it is no need to climb to the left corner, now we use the `position` parameter: if the car reach some negative position, we just push it to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:35:45.803294Z",
     "start_time": "2020-04-03T22:35:45.787817Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define an error function using the pole velocity as the unique parameter to penalize the model\n",
    "def assing_action_alt(obs, pre_obs, pre_action):\n",
    "    pos, vel = obs\n",
    "    pre_pos, pre_vel = pre_obs\n",
    "    if (pre_vel > 0) and (vel <= 0):\n",
    "        return 0\n",
    "    elif (pre_vel > 0) and (vel > 0):\n",
    "        return 2\n",
    "    elif (pre_vel <= 0) and (vel >= 0):\n",
    "        return 2\n",
    "    else:\n",
    "        if pos < -0.9:\n",
    "            return 2\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T22:57:38.859976Z",
     "start_time": "2020-04-03T22:57:34.762912Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE OF STEPS: 104.7 WITH INIT ACTION CUSTOMIZED\n",
      "STD OF STEPS: 12.76 WITH INIT ACTION CUSTOMIZED\n",
      "MINIMUM OF STEPS: 83 WITH INIT ACTION CUSTOMIZED\n",
      "MAXIMUM OF STEPS: 116 WITH INIT ACTION CUSTOMIZED\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "steps_array = []\n",
    "for i in range(1000):\n",
    "    obs = my_env.reset()\n",
    "    init_action = 2\n",
    "    if obs[0] > -0.475:\n",
    "        init_action = 0\n",
    "    action = init_action\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "#         my_env.render()\n",
    "        new_obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps += 1\n",
    "        action = assing_action_alt(obs=new_obs, pre_obs=obs, pre_action=action)\n",
    "        \n",
    "    steps_array.append(steps)\n",
    "# my_env.close()\n",
    "best_avg_reward = np.mean(steps_array)\n",
    "print('AVERAGE OF STEPS:', np.round(np.mean(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('STD OF STEPS:', np.round(np.std(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MINIMUM OF STEPS:', np.round(np.min(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')\n",
    "print('MAXIMUM OF STEPS:', np.round(np.max(steps_array), 2), 'WITH INIT ACTION CUSTOMIZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to do, is hyperparameter tuning for thw two parameters: `init_pos` (in `init_action` decision) and `pos` (in `assign_action` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "Now we will implement a random search for the weights of a linear model with the parameters of the car i.e.\n",
    "\n",
    "$$a = \\sigma(w_0 + w_1c_v + w_2c_p)$$\n",
    "\n",
    "In this example, we do not have bias $w_0$ i.e. $w_0=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:52:30.548674Z",
     "start_time": "2020-03-27T22:52:30.545093Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_action(obs, weights):\n",
    "    x, y = obs\n",
    "    \n",
    "    y = np.dot(obs, weights)\n",
    "    if y > 0:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.493053Z",
     "start_time": "2020-03-27T23:02:30.280599Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vectors and values relevant for final analysis\n",
    "steps_best_sample = None\n",
    "steps_best_avg = math.inf\n",
    "step_avgs = []\n",
    "best_weights = None\n",
    "\n",
    "#init my_env\n",
    "obs = my_env.reset()\n",
    "\n",
    "for r_i in range(10):\n",
    "    \n",
    "    #Init random weights between [-1,1] for each one of the parameters of the models\n",
    "    random_weights = np.random.random(len(obs))*2 - 1 \n",
    "    #print(random_weights)\n",
    "    steps_reps = []\n",
    "    for i in range(100):\n",
    "        obs = my_env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = assign_action(obs, weights=random_weights)\n",
    "            obs, rew, done, _ = my_env.step(action=action)\n",
    "        steps_reps.append(steps)\n",
    "    \n",
    "    step_avgs.append(np.mean(steps_reps))\n",
    "    if np.mean(steps_reps) < steps_best_avg:\n",
    "        steps_best_avg = np.mean(steps_reps)\n",
    "        steps_best_sample = steps_reps\n",
    "        best_weights = random_weights\n",
    "    \n",
    "    if (r_i+1) % 50 == 0:\n",
    "        print('ITERATION NUMBER', r_i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:02:43.509015Z",
     "start_time": "2020-03-27T23:02:43.495326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST AVERAGE 200.0 WITH WEIGHTS [-0.90102733  0.16965663]\n"
     ]
    }
   ],
   "source": [
    "print('BEST AVERAGE', steps_best_avg, 'WITH WEIGHTS', best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Random search for weights of linear model does not work very well, at least not as well as out intelligent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning: Tabular Method\n",
    "\n",
    "Let's implement the tabular method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limits and Bins\n",
    "\n",
    "Construction of the bins for each one of the parameters of the model. In particular, given that `pole_vel` and `car_vel` do not have intervals, we will iterate and calculate the `min` and `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:26:44.038441Z",
     "start_time": "2020-04-06T03:26:33.305088Z"
    }
   },
   "outputs": [],
   "source": [
    "min_pos, max_pos = [-1.2, 0.6]\n",
    "min_vel, max_vel = [-0.07, 0.07]\n",
    "\n",
    "#Exercise: Determine how many steps, on average, are taken, when\n",
    "#actions are randomly sampled\n",
    "vels = []\n",
    "pole_vels = []\n",
    "angles = []\n",
    "for i in range(1000):\n",
    "    my_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        obs, rew, done, _ = my_env.step(action=my_env.action_space.sample())\n",
    "        steps += 1\n",
    "my_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the limit for our `box`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:07.858566Z",
     "start_time": "2020-04-06T04:22:07.849758Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the bins for each one of the parameters\n",
    "num_bins = 10\n",
    "pos_bins = np.linspace(min_pos, max_pos, num_bins)\n",
    "vel_bins = np.linspace(min_vel, max_vel, num_bins)\n",
    "\n",
    "#Creates a list with the bins of each parameters in the order that the parameters are presented\n",
    "obs_bins = [pos_bins, vel_bins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "Let's create some relevant classes for the __Tabular Method__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:08.637991Z",
     "start_time": "2020-04-06T04:22:08.619742Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_q_tab(env, number_of_bins, randomness=True):\n",
    "    n_obs = env.observation_space.shape[0]\n",
    "    n_obs_bins = (number_of_bins+1)**n_obs\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    q_tab = np.random.uniform(-1,1, size=(n_obs_bins, n_actions))\n",
    "    q_tab = pd.DataFrame(q_tab)\n",
    "    \n",
    "    str_l = list(range(0,number_of_bins+1))\n",
    "    combinations = set(list(combinations_with_replacement(str_l*n_obs, n_obs)))\n",
    "    combinations_join = ['-'.join([str(n) for n in c]) for c in combinations]\n",
    "    \n",
    "    q_tab['INDEX'] = combinations_join\n",
    "    \n",
    "    q_tab = q_tab.set_index('INDEX')\n",
    "    return q_tab\n",
    "\n",
    "def build_state(states):\n",
    "    states_str = '-'.join([str(int(s)) for s in states])\n",
    "    return states_str\n",
    "\n",
    "def to_bin(value, my_bin):\n",
    "    return np.digitize(value, my_bin)\n",
    "\n",
    "def transform_obs(obs, obs_bins=obs_bins):\n",
    "    if len(obs) != len(obs_bins):\n",
    "        return 'ERROR'\n",
    "    else:\n",
    "        obs_to_bins = []\n",
    "        for idx,_ in enumerate(obs):\n",
    "            obs_to_bins.append(to_bin(obs[idx], obs_bins[idx]))\n",
    "        return build_state(obs_to_bins)\n",
    "\n",
    "def predict(state, q_tab):\n",
    "    x = transform_obs(state)\n",
    "    return np.array(q_tab.loc[x])\n",
    "\n",
    "def update(state, a, g, q_tab, l_r=0.01):\n",
    "    x = transform_obs(state)\n",
    "    q_tab.loc[x, a] += l_r*(g - q_tab.loc[x, a])\n",
    "    \n",
    "def sample_action(env, state, eps, q_tab):\n",
    "    if np.random.random() < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        a_p = predict(state, q_tab)\n",
    "        return q_tab.columns[np.argmax(np.array(a_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:09.101403Z",
     "start_time": "2020-04-06T04:22:09.090968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF Q-TAB IS (121, 3) AND COLUMN NAMES ARE Index([0, 1, 2], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "q_tab = construct_q_tab(env=my_env, number_of_bins=num_bins)\n",
    "q_tab.iloc[:,1] = -10e+5\n",
    "\n",
    "print('SHAPE OF Q-TAB IS', q_tab.shape, 'AND COLUMN NAMES ARE', q_tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:22:17.108859Z",
     "start_time": "2020-04-06T04:22:17.101166Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, q_tab, eps, gamma):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac = sample_action(env, state=obs, eps=eps, q_tab=q_tab)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        if (steps==199):\n",
    "            rew = -100\n",
    "            \n",
    "        \n",
    "        if done and (steps<199):\n",
    "            rew = 1000\n",
    "        \n",
    "        #Update the model\n",
    "        g = rew + gamma*np.max(predict(obs, q_tab))\n",
    "        update(state=pre_obs, a=ac, g=g, q_tab=q_tab)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:30:29.222687Z",
     "start_time": "2020-04-06T04:22:17.314370Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ITERATION - -200.0 TOTAL REWARD\n",
      "200 ITERATION - -200.0 TOTAL REWARD\n",
      "300 ITERATION - -200.0 TOTAL REWARD\n",
      "400 ITERATION - -198.39 TOTAL REWARD\n",
      "500 ITERATION - -198.16 TOTAL REWARD\n",
      "600 ITERATION - -200.0 TOTAL REWARD\n",
      "700 ITERATION - -193.41 TOTAL REWARD\n",
      "800 ITERATION - -187.08 TOTAL REWARD\n",
      "900 ITERATION - -185.92 TOTAL REWARD\n",
      "1000 ITERATION - -173.35 TOTAL REWARD\n",
      "1100 ITERATION - -171.69 TOTAL REWARD\n",
      "1200 ITERATION - -170.16 TOTAL REWARD\n",
      "1300 ITERATION - -173.01 TOTAL REWARD\n",
      "1400 ITERATION - -178.13 TOTAL REWARD\n",
      "1500 ITERATION - -184.87 TOTAL REWARD\n",
      "1600 ITERATION - -173.76 TOTAL REWARD\n",
      "1700 ITERATION - -180.77 TOTAL REWARD\n",
      "1800 ITERATION - -176.7 TOTAL REWARD\n",
      "1900 ITERATION - -166.88 TOTAL REWARD\n",
      "2000 ITERATION - -172.68 TOTAL REWARD\n",
      "2100 ITERATION - -162.66 TOTAL REWARD\n",
      "2200 ITERATION - -163.14 TOTAL REWARD\n",
      "2300 ITERATION - -164.19 TOTAL REWARD\n",
      "2400 ITERATION - -176.29 TOTAL REWARD\n",
      "2500 ITERATION - -158.33 TOTAL REWARD\n"
     ]
    }
   ],
   "source": [
    "## ITERATE AND LEARN\n",
    "total_rewards = []\n",
    "gamma = 0.9999\n",
    "\n",
    "for i in range(2500):\n",
    "    eps = 1.0/np.sqrt(i+1)\n",
    "    total_reward = play_game(env=my_env, q_tab=q_tab, eps=eps, gamma=gamma)\n",
    "    total_rewards.append(total_reward)\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-99:i+1]), 'TOTAL REWARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T04:30:32.173768Z",
     "start_time": "2020-04-06T04:30:31.856455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:04.898661Z",
     "start_time": "2020-04-10T03:20:04.881555Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:05.471821Z",
     "start_time": "2020-04-10T03:20:05.454208Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:12.905067Z",
     "start_time": "2020-04-10T03:20:12.880362Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_models(env, featurizer, scaler, n_actions=None,l_r=0.01):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        model = SGDRegressor(learning_rate=l_r)\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        state_feature = featurizer.transform(state_scaled)\n",
    "        model.partial_fit(state_feature, [0])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_feature, [g])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        \n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T03:20:17.833306Z",
     "start_time": "2020-04-10T03:20:17.818579Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma, n_actions=None, actions=None, updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    \n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #Update the model\n",
    "        if updt:\n",
    "            g = rew + gamma*np.max(predict(state=obs, featurizer=featurizer, scaler=scaler, models=models))\n",
    "            update(state=pre_obs, idx_a=idx_ac, g=g, featurizer=featurizer, scaler=scaler, models=models)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T04:05:01.144374Z",
     "start_time": "2020-04-10T03:53:50.499247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "50 ITERATION - -200.0 50-MOVING AVG REWARD\n",
      "100 ITERATION - -196.02 50-MOVING AVG REWARD\n",
      "150 ITERATION - -150.92 50-MOVING AVG REWARD\n",
      "200 ITERATION - -138.9 50-MOVING AVG REWARD\n",
      "250 ITERATION - -123.52 50-MOVING AVG REWARD\n",
      "300 ITERATION - -129.62 50-MOVING AVG REWARD\n",
      "350 ITERATION - -124.72 50-MOVING AVG REWARD\n",
      "400 ITERATION - -127.64 50-MOVING AVG REWARD\n",
      "450 ITERATION - -122.56 50-MOVING AVG REWARD\n",
      "500 ITERATION - -122.58 50-MOVING AVG REWARD\n",
      "550 ITERATION - -119.2 50-MOVING AVG REWARD\n",
      "600 ITERATION - -117.56 50-MOVING AVG REWARD\n",
      "650 ITERATION - -117.46 50-MOVING AVG REWARD\n",
      "700 ITERATION - -114.08 50-MOVING AVG REWARD\n",
      "750 ITERATION - -115.36 50-MOVING AVG REWARD\n",
      "800 ITERATION - -113.56 50-MOVING AVG REWARD\n",
      "850 ITERATION - -113.76 50-MOVING AVG REWARD\n",
      "900 ITERATION - -111.76 50-MOVING AVG REWARD\n",
      "950 ITERATION - -111.4 50-MOVING AVG REWARD\n",
      "1000 ITERATION - -109.52 50-MOVING AVG REWARD\n",
      "1050 ITERATION - -109.68 50-MOVING AVG REWARD\n",
      "1100 ITERATION - -105.24 50-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 'invscaling'\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 10000\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 50\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[0.5, 0.4, 0.3, 0.2, 0.1, 0.05],\n",
    "                               num_components=75)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r, n_actions=len(actions))\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.1*(0.9**(i+1))\n",
    "    gamma = 0.99\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T04:06:20.446943Z",
     "start_time": "2020-04-10T04:06:05.523350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO CHECK---\n",
      "ITERATION 25\n",
      "ITERATION 50\n",
      "ITERATION 75\n",
      "ITERATION 100\n",
      "RESULTS---\n",
      "AVERAGE OF REWARD: -108.67\n",
      "STD OF REWARD: 10.95\n",
      "MINIMUM OF REWARD: -116.0\n",
      "MAXIMUM OF REWARD: -83.0\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing results produced by our __RBF Neural Network__ with a pretty good avergare reward (compared with our best intelligent system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs & Q-Learning\n",
    "\n",
    "In this section, I'll create a Neural Network a let that the it learn its own features instead of providing it the radial basis kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:30:08.624519Z",
     "start_time": "2020-04-09T15:30:08.617548Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T23:10:57.079937Z",
     "start_time": "2020-04-09T23:10:57.063194Z"
    }
   },
   "outputs": [],
   "source": [
    "#We only modify our sgd_regressor class using Theano code \n",
    "class NN():\n",
    "    def __init__(self, input_shape, l_r=0.01, layers=[50, 100, 100, 50],\n",
    "                 drop_out=0.1):\n",
    "        self.l_r = l_r\n",
    "        self.step = 0\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.sgd = SGD(lr=l_r, decay=0)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(units=self.layers[0], input_shape=input_shape, activation='tanh',\n",
    "                             kernel_initializer='lecun_uniform'))\n",
    "        for idx in range(1,len(layers)):\n",
    "            self.model.add(Dense(self.layers[idx], activation='tanh'))\n",
    "            if drop_out:\n",
    "                self.model.add(Dropout(drop_out))\n",
    "        \n",
    "        self.model.add(Dense(1, activation='tanh'))\n",
    "        \n",
    "        self.model.compile(loss='mse', optimizer=self.sgd)\n",
    "        \n",
    "    def partial_fit(self, x, y):\n",
    "        mod_x = x\n",
    "        mod_y = y.reshape(y.shape[0],1)\n",
    "        self.model.train_on_batch(mod_x, mod_y)\n",
    "        self.step += 1\n",
    "        \n",
    "    def predict(self, x):\n",
    "        mod_x = x\n",
    "        return self.model.predict(mod_x)[0]\n",
    "\n",
    "def init_models(env, scaler, n_actions=None, l_r=0.01, layers=[50, 100, 100, 50], drop_out=0.1):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        input_shape = state_scaled[0].shape\n",
    "        model = NN(l_r=l_r, input_shape=input_shape, layers=layers, drop_out=drop_out)\n",
    "        #model.partial_fit(scaled, [0])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_scaled)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_scaled, np.array([g]))\n",
    "    \n",
    "def sample_action(env, state, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, scaler, models)\n",
    "        \n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T23:48:39.225438Z",
     "start_time": "2020-04-09T23:48:39.208225Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, scaler, eps, gamma, n_actions=None, actions=None, updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    pre_ac = None\n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        \n",
    "        pre_pos, pre_vel = pre_obs\n",
    "        pos, vel = obs\n",
    "        \n",
    "        #Update the model\n",
    "        if updt:\n",
    "            g = (rew + gamma*np.max(predict(state=obs, scaler=scaler, models=models)))\n",
    "            update(state=pre_obs, idx_a=idx_ac, g=g, scaler=scaler, models=models)\n",
    "        \n",
    "        steps += 1\n",
    "        pre_ac = ac\n",
    "    \n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T00:40:55.799398Z",
     "start_time": "2020-04-09T23:48:40.084612Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "10 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "20 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "30 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "40 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "50 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "60 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "70 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "80 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "90 ITERATION - -200.0 10-MOVING AVG REWARD\n",
      "100 ITERATION - -200.0 10-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 0.01\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 50\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "models = init_models(env=my_env, scaler=scaler, l_r=l_r, n_actions=len(actions),\n",
    "                     layers=[1000, 1000], drop_out=0.01)\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.1*(0.9**(i+1))\n",
    "    gamma = 0.99\n",
    "    total_reward = play_game(env=my_env, models=models, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T22:26:48.915055Z",
     "start_time": "2020-04-09T22:26:28.087Z"
    }
   },
   "outputs": [],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was expecting, the result are pretty bad, it is like the NN is suffering the __Catastrofic Frogetting__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Steps Method: RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T05:28:14.202175Z",
     "start_time": "2020-04-10T05:28:14.196932Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T05:28:14.727567Z",
     "start_time": "2020-04-10T05:28:14.721230Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T17:46:46.989507Z",
     "start_time": "2020-04-10T17:46:46.965007Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_models(env, featurizer, scaler, n_actions=None, l_r='invscaling', eta=0.01):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        model = SGDRegressor(learning_rate=l_r, eta0=eta)\n",
    "        state_scaled = scaler.transform([env.reset()])\n",
    "        state_feature = featurizer.transform(state_scaled)\n",
    "        model.partial_fit(state_feature, [0])\n",
    "        models.append(model)\n",
    "    return models    \n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    #assert(len(state_feature.shape) == 2)\n",
    "    models[idx_a].partial_fit(state_feature, [g])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:40:07.598840Z",
     "start_time": "2020-04-11T23:40:07.583957Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma, steps=5, n_actions=None, actions=None,\n",
    "              updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rewards = []\n",
    "    iters = 0\n",
    "    states = []\n",
    "    idx_actions = []\n",
    "    total_reward = 0\n",
    "    \n",
    "    gammas = np.repeat(gamma, steps)**np.arange(steps)\n",
    "    #print(gammas)\n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        states.append(obs)\n",
    "        idx_actions.append(idx_ac)\n",
    "        \n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        \n",
    "        rewards.append(rew)\n",
    "        \n",
    "        if updt:\n",
    "            if len(rewards) >= steps:\n",
    "                rew_accumulated = gammas.dot(rewards[-steps:])\n",
    "                g = rew_accumulated + (gamma**steps)*(np.max(predict(state=obs, featurizer=featurizer,\n",
    "                                                             scaler=scaler, models=models)))\n",
    "                update(state=states[-steps], idx_a=idx_actions[-steps], g=g, featurizer=featurizer,\n",
    "                       scaler=scaler, models=models)\n",
    "        total_reward += rew\n",
    "        iters += 1\n",
    "    \n",
    "    if updt and (steps > 1):\n",
    "        rewards = rewards[-steps+1:]\n",
    "        idx_actions = idx_actions[-steps+1:]\n",
    "        states = states[-steps+1:]\n",
    "        if iters <= 199:\n",
    "            rewards[-1] = (200 - iters)/200\n",
    "            while len(rewards) > 0:\n",
    "                rew_accumulated = gammas[:len(rewards)].dot(rewards)\n",
    "                g = rew_accumulated\n",
    "                update(state=states[0], idx_a=idx_actions[0], g=g, featurizer=featurizer, scaler=scaler,\n",
    "                       models=models)\n",
    "                rewards.pop(0)\n",
    "                idx_actions.pop(0)\n",
    "                states.pop(0)\n",
    "        else:\n",
    "            while len(rewards) > 0:\n",
    "                rew_accumulated = gammas.dot(rewards + [-100]*(steps - len(rewards)))\n",
    "                g = rew_accumulated\n",
    "                update(state=states[0], idx_a=idx_actions[0], g=g, featurizer=featurizer, scaler=scaler,\n",
    "                       models=models)\n",
    "                rewards.pop(0)\n",
    "                idx_actions.pop(0)\n",
    "                states.pop(0)\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations and Learning\n",
    "\n",
    "This section implements our learning algorithm and check its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:43:54.951051Z",
     "start_time": "2020-04-11T23:40:08.645325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "100 ITERATION - -174.12 100-MOVING AVG REWARD\n",
      "200 ITERATION - -130.68 100-MOVING AVG REWARD\n",
      "300 ITERATION - -128.81 100-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 'constant'\n",
    "eta = 0.0005\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 300\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 100\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125],\n",
    "                               num_components=150)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "n_weights = featurization['TRANSFORM_FEATURES'].shape[1]\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r, n_actions=len(actions),\n",
    "                     eta=eta)\n",
    "\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.01*(0.9**(i+1))\n",
    "    gamma = 0.99\n",
    "    steps = 3\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, steps=steps)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')\n",
    "        if np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:43:55.227803Z",
     "start_time": "2020-04-11T23:43:54.953787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:44:20.554936Z",
     "start_time": "2020-04-11T23:43:55.233283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO CHECK---\n",
      "ITERATION 25\n",
      "ITERATION 50\n",
      "ITERATION 75\n",
      "ITERATION 100\n",
      "RESULTS---\n",
      "AVERAGE OF REWARD: -118.7\n",
      "STD OF REWARD: 2.39\n",
      "MINIMUM OF REWARD: -129.0\n",
      "MAXIMUM OF REWARD: -117.0\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                             eps=eps, gamma=gamma, n_actions=len(actions), actions=actions, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-Lambda Method: RBF NNs & Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:48:53.459890Z",
     "start_time": "2020-04-11T23:48:53.445324Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampler_observations(env, sample_size, standardize=True):\n",
    "    '''\n",
    "    Generates a sample of states of an environement or game\n",
    "    '''\n",
    "    sample = np.array([env.observation_space.sample() for idx in range(sample_size)])\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_sample = scaler.fit_transform(sample)\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample, 'SCALED_SAMPLE': scaled_sample}\n",
    "    else:\n",
    "        dic = {'SCALER': scaler, 'SAMPLE': sample}\n",
    "    print('GENERATED DATA WITH SHAPE', sample.shape)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:48:53.820589Z",
     "start_time": "2020-04-11T23:48:53.810206Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_featurizer(data, gammas, num_components):\n",
    "    '''\n",
    "    Generates a rbf featurizer for different gammas (variances) and fit data with it\n",
    "    '''\n",
    "    features = []\n",
    "    for idx, g in enumerate(gammas):\n",
    "        rbf_name = 'RBF-' + str(idx)\n",
    "        s = RBFSampler(gamma=g, n_components=num_components)\n",
    "        rbf = (rbf_name, s)\n",
    "        features.append(rbf)\n",
    "    featurizer = FeatureUnion(features)\n",
    "    t_features = featurizer.fit_transform(data)\n",
    "    dic = {'FEATURIZER': featurizer, 'TRANSFORM_FEATURES': t_features}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T23:52:19.927026Z",
     "start_time": "2020-04-11T23:52:19.913310Z"
    }
   },
   "outputs": [],
   "source": [
    "class td_lambda_regressor():\n",
    "    def __init__(self, n_weights, l_r=0.01):\n",
    "        self.weights = np.random.rand(n_weights)/np.power(n_weights, 0.5)\n",
    "        self.l_r = l_r\n",
    "        self.step = 0\n",
    "        \n",
    "    \n",
    "    def partial_fit(self, x, y, eligibilities_a):\n",
    "        estimated = x.dot(self.weights)\n",
    "        difference = (y - estimated)\n",
    "        trace = difference*eligibilities_a\n",
    "        self.weights += (self.l_r)*trace\n",
    "        self.step += 1\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return x.dot(self.weights)\n",
    "    \n",
    "def init_models(env, n_weights, featurizer, scaler, n_actions=None, l_r=0.01):\n",
    "    models = []\n",
    "    if n_actions==None:\n",
    "        n_actions = env.action_space.n\n",
    "    \n",
    "    for i in range(n_actions):\n",
    "        model = td_lambda_regressor(n_weights=n_weights, l_r=l_r)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predict(state, featurizer, scaler, models):\n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    predictions = np.array([m.predict(state_feature)[0] for m in models])\n",
    "    return predictions\n",
    "\n",
    "def update(state, idx_a, g, featurizer, scaler, models, eligibilities, factor):\n",
    "    \n",
    "    state_scaled = scaler.transform([state])\n",
    "    state_feature = featurizer.transform(state_scaled)\n",
    "    eligibilities *= factor\n",
    "    eligibilities[idx_a] += state_feature[0]\n",
    "    models[idx_a].partial_fit(state_feature, [g], eligibilities_a=eligibilities[idx_a])\n",
    "    \n",
    "def sample_action(env, state, featurizer, scaler, models, eps, actions=None):\n",
    "    if sum(actions == None) != 0:\n",
    "        actions = np.array(list(range(0,env.action_space.n)))\n",
    "    if np.random.random() < eps:\n",
    "        idx = np.random.choice(len(actions), size=1)[0]\n",
    "        return [actions[idx], idx]\n",
    "    else:\n",
    "        predictions = predict(state, featurizer, scaler, models)\n",
    "        return [actions[np.argmax(predictions)], np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T01:25:13.183160Z",
     "start_time": "2020-04-12T01:25:13.169259Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_game(env, models, featurizer, scaler, eps, gamma, td_lambda, eligibilities, n_actions=None,\n",
    "              actions=None, updt=True):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    iters = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        ac, idx_ac = sample_action(env=env, state=obs, featurizer=featurizer, scaler=scaler,\n",
    "                                   models=models, eps=eps, actions=actions)\n",
    "        pre_obs = obs.copy()\n",
    "        obs, rew, done, _ = my_env.step(action=ac)\n",
    "        total_reward += rew\n",
    "        \n",
    "        #if iters == 199:\n",
    "            #rew = -1000\n",
    "        #elif done:\n",
    "            #rew = (200 - iters)\n",
    "        \n",
    "        if updt:\n",
    "            g = rew + gamma*np.max(predict(state=obs, featurizer=featurizer, scaler=scaler, models=models))\n",
    "            update(state=pre_obs, idx_a=idx_ac, g=g, featurizer=featurizer, scaler=scaler, models=models,\n",
    "                   eligibilities=eligibilities, factor=gamma*td_lambda)\n",
    "        iters += 1\n",
    "    return [total_reward, eligibilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations and Learning\n",
    "\n",
    "This section implements our learning algorithm and check its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:05:14.034597Z",
     "start_time": "2020-04-12T02:59:05.747721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED DATA WITH SHAPE (50000, 2)\n",
      "READY TO LEARN---\n",
      "100 ITERATION - -200.0 100-MOVING AVG REWARD\n",
      "200 ITERATION - -180.73 100-MOVING AVG REWARD\n",
      "300 ITERATION - -121.77 100-MOVING AVG REWARD\n",
      "400 ITERATION - -116.72 100-MOVING AVG REWARD\n",
      "500 ITERATION - -110.02 100-MOVING AVG REWARD\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND LEARN\n",
    "comparision_avg_reward = -109\n",
    "\n",
    "total_rewards = []\n",
    "l_r = 0.001\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 1000\n",
    "size = 50000\n",
    "sample = sampler_observations(env=my_env, sample_size=size)\n",
    "actions = np.array([0,2])\n",
    "printer = 100\n",
    "\n",
    "sample_data = sample['SCALED_SAMPLE']\n",
    "scaler = sample['SCALER']\n",
    "featurization = rbf_featurizer(data=sample_data, gammas=[1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125],\n",
    "                               num_components=150)\n",
    "featurizer = featurization['FEATURIZER']\n",
    "n_weights = featurization['TRANSFORM_FEATURES'].shape[1]\n",
    "eligibilities = np.zeros((len(actions), n_weights))\n",
    "td_lambda = 0.1\n",
    "gamma = 0.99\n",
    "models = init_models(env=my_env, featurizer=featurizer, scaler=scaler, l_r=l_r, n_actions=len(actions),\n",
    "                     n_weights=n_weights)\n",
    "\n",
    "\n",
    "'''\n",
    "ITERATE AND LEARN USING RBF NN'S\n",
    "'''\n",
    "print('READY TO LEARN---')\n",
    "for i in range(iterations):\n",
    "    eps = 0.01*(0.9**(i+1))\n",
    "    total_reward, eligibilities = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                                            eps=eps, gamma=gamma, n_actions=len(actions), actions=actions,\n",
    "                                            eligibilities=eligibilities, td_lambda=td_lambda)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if ((i+1) >= printer) and (np.mean(total_rewards[i-(printer-1):i+1]) > (comparision_avg_reward)):\n",
    "            break\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print(i+1, 'ITERATION -', np.mean(total_rewards[i-(printer-1):i+1]),\n",
    "              str(printer) + '-MOVING AVG REWARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:05:18.717268Z",
     "start_time": "2020-04-12T03:05:18.531463Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_running_avg(np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:05:40.500419Z",
     "start_time": "2020-04-12T03:05:25.460177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY TO CHECK---\n",
      "ITERATION 25\n",
      "ITERATION 50\n",
      "ITERATION 75\n",
      "ITERATION 100\n",
      "RESULTS---\n",
      "AVERAGE OF REWARD: -106.42\n",
      "STD OF REWARD: 12.19\n",
      "MINIMUM OF REWARD: -117.0\n",
      "MAXIMUM OF REWARD: -83.0\n"
     ]
    }
   ],
   "source": [
    "#ITERATE AND CHECK\n",
    "total_rewards = []\n",
    "printer = 25\n",
    "eps = -1\n",
    "\n",
    "#GENERATE SAMPLES\n",
    "iterations = 100\n",
    "'''\n",
    "ITERATE AND CHECK USING RBF NN'S\n",
    "'''\n",
    "print('READY TO CHECK---')\n",
    "for i in range(iterations):\n",
    "    total_reward, eligibilities = play_game(env=my_env, models=models, featurizer=featurizer, scaler=scaler,\n",
    "                                            eps=eps, gamma=gamma, n_actions=len(actions), actions=actions,\n",
    "                                            eligibilities=eligibilities, td_lambda=td_lambda, updt=False)\n",
    "    total_rewards.append(total_reward)\n",
    "    \n",
    "    if (i+1) % printer == 0:\n",
    "        print('ITERATION', i+1)\n",
    "\n",
    "print('RESULTS---')\n",
    "print('AVERAGE OF REWARD:', np.round(np.mean(total_rewards), 2))\n",
    "print('STD OF REWARD:', np.round(np.std(total_rewards), 2))\n",
    "print('MINIMUM OF REWARD:', np.round(np.min(total_rewards), 2))\n",
    "print('MAXIMUM OF REWARD:', np.round(np.max(total_rewards), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
